from fastapi import FastAPI, UploadFile, File, Query, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse
from pydantic import BaseModel
from typing import List, Optional
from pymilvus import Collection, connections, utility
from txtai.embeddings import Embeddings
import numpy as np, os, shutil
import uvicorn

import milvus_function as ms

app = FastAPI()

# =====================================
# CORS (React ì—°ê²° ì§€ì›)
# =====================================
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], allow_methods=["*"], allow_headers=["*"]
)

UPLOAD_DIR= ms.DATA_DIR
ALLOWED_EXT=ms.ALLOWED_EXT

# ===================================== 
# txtai ëª¨ë¸ Â· Milvus ì—°ê²° ì´ˆê¸°í™”
# =====================================
print("\nğŸš€ Loading txtai model & connecting Milvus...")

embeddings = ms.initialize_embeddings()

ms.connect_milvus()
collection = ms.setup_milvus_collection()

print("âœ… Ready â†’ API Online\n")


# =====================================
# íŒŒì¼ ì—…ë¡œë“œ (/upload)
# =====================================
@app.post("/upload")
def upload_file(
    files: List[UploadFile] = File(...),
    session_id: str = Form("default") # session_id ì¶”ê°€
):
    
    saved_files = []
    errors = []

    # ì„¸ì…˜ë³„ í´ë” ìƒì„±
    session_dir = os.path.join(UPLOAD_DIR, session_id)
    os.makedirs(session_dir, exist_ok=True)

    for file in files:
        ext = file.filename.split(".")[-1].lower()
        if ext not in ALLOWED_EXT:
            errors.append(f"âŒ {file.filename}: ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ ({ext})")
            continue

        save_path = f"{session_dir}/{file.filename}"
        with open(save_path, "wb") as f:
            shutil.copyfileobj(file.file, f)
        
        saved_files.append(file.filename)

    return {
        "status": "completed",
        "saved": saved_files,
        "errors": errors,
        "session_id": session_id,
        "info": "ğŸ“Œ íŒŒì¼ ì €ì¥ì™„ë£Œ â†’ /reindex í˜¸ì¶œ ì‹œ ì¸ë±ì‹± ìˆ˜í–‰"
    }

# =====================================
# ğŸ“‚ íŒŒì¼ ë‹¤ìš´ë¡œë“œ/ì—´ê¸° (ì¶”ê°€ë¨)
# =====================================
@app.get("/files/{session_id}/{filename}")
def get_file(session_id: str, filename: str):
    file_path = os.path.join(UPLOAD_DIR, session_id, filename)
    if os.path.exists(file_path):
        return FileResponse(file_path)
    return {"error": "File not found"}


# =====================================
# ì¸ë±ì‹± (ì¦ë¶„ ë°©ì‹)
# =====================================
@app.get("/reindex")
def reindex(session_id: str = "default"):

    global collection, embeddings  

    # ì„¸ì…˜ë³„ í´ë” ìŠ¤ìº”
    session_dir = os.path.join(UPLOAD_DIR, session_id)
    if not os.path.exists(session_dir):
        return {"status": "No documents found for this session"}

    documents = ms.load_all_documents(session_dir, session_id)
    if not documents:
        return {"status": "No new documents"}
    
    ms.vectorize_and_index_via_txtai(embeddings, collection, documents)

    return {"status": "Success", "indexed": len(documents)}


# =====================================
# ğŸ” ê²€ìƒ‰
# =====================================
@app.get("/search")
def search(q: str, session_id: str = "default", top_k: int = 5):
    global embeddings, collection
    
    try:
        # ì¿¼ë¦¬ ë²¡í„°í™”
        qvec = embeddings.transform(q)
        if isinstance(qvec, np.ndarray):
            qvec = qvec.tolist()

        # session_id í•„í„°ë§ ì¶”ê°€
        expr = f'session_id == "{session_id}"'

        results = collection.search(
            data=[qvec],
            anns_field="vector",
            param={"metric_type":"IP","params":{"nprobe":16}},
            limit=top_k,
            expr=expr, # í•„í„° ì ìš©
            output_fields=["filename","path","doc_type","text","session_id"]
        )

        if not results or len(results[0]) == 0:
            return {"results": [], "message":"ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ"}

        out=[]
        for hit in results[0]:
            e = hit.entity
            filename = e.get("filename")
            sid = e.get("session_id")
            out.append({
                "score": float(hit.score),
                "file":  filename,
                "path":  e.get("path"),
                "type":  e.get("doc_type"),
                "preview": e.get("text")[:200].replace("\n"," "),
                # [ì¶”ê°€] íŒŒì¼ì„ ì—´ ìˆ˜ ìˆëŠ” URL ì œê³µ (ì„¸ì…˜ ID í¬í•¨)
                "url": f"http://localhost:8000/files/{sid}/{filename}" 
            })
        return {"results":out}

    except Exception as e:
        return {"error": str(e)}


# =====================================
# ğŸ“„ ë¬¸ì„œ ëª©ë¡ ì¡°íšŒ
# =====================================
@app.get("/documents")
def list_documents(session_id: str = "default", limit: int = 100):

    # Milvus ì¿¼ë¦¬ limit ë³´í˜¸
    limit = min(limit, 16384)

    # session_id í•„í„°ë§
    expr = f'session_id == "{session_id}"'

    # id, filename, doc_type, text ë§Œ ê°€ì ¸ì˜¤ê¸°
    rows = collection.query(
        expr=expr,
        output_fields=["id", "filename", "doc_type", "text"],
        limit=limit
    )

    docs = []
    for r in rows:
        docs.append({
            "id": str(r["id"]),                         # [ìˆ˜ì •] JS ì •ë°€ë„ ë¬¸ì œë¡œ ë¬¸ìì—´ ë³€í™˜
            "filename": r["filename"],                  # íŒŒì¼ëª…
            "preview": r["text"][:20].replace("\n", " "),  # 20ì ì œí•œ
            "type": r["doc_type"]                       # í™•ì¥ì
        })

    return {"count": len(docs), "documents": docs}


# =====================================
# ğŸ“Š í™•ì¥ìë³„ í†µê³„
# =====================================
@app.get("/stats")
def stats():

    total=collection.num_entities
    if total==0:
        return {"total_docs":0,"by_extension":{}}

    limit=min(total,16384)
    rows=collection.query(expr="id >= 0",output_fields=["doc_type"],limit=limit)

    stat={}
    for r in rows:
        ext=r["doc_type"]
        stat[ext]=stat.get(ext,0)+1

    return {"total_docs":len(rows),"by_extension":stat}

@app.get("/vectors")
def vectors(limit: int = 10, dim: int = 10):
    limit = min(limit, 16384)

    rows = collection.query(
        expr="id >= 0",
        output_fields=["id", "filename", "vector"],
        limit=limit
    )

    vectors = []
    for r in rows:
        vec = r["vector"][:dim]    #  ì• dimê°œë§Œ ì¶œë ¥
        vectors.append({
            "id": str(r["id"]), # [ìˆ˜ì •] JS ì •ë°€ë„ ë¬¸ì œë¡œ ë¬¸ìì—´ ë³€í™˜
            "filename": r["filename"],
            "vector_preview": vec,
            "vector_dimensions": len(r["vector"])
        })

    return {"count": len(vectors), "vectors": vectors}


# ======================================================
# â‘  clear : Collection ì „ì²´ ì‚­ì œ â†’ ì´ˆê¸°í™”
# ======================================================
@app.get("/clear")
def clear_db():
    deleted = ms.drop_milvus_collection_and_count()
    return {
        "status": "CLEARED" if deleted > 0 else "NO ACTION",
        "deleted_docs": deleted, 
        "message": "Vector DB reset." if deleted > 0 else "Collection was already empty."
    }


# ======================================================
# â‘¡ delete : íŠ¹ì • íŒŒì¼ ë°ì´í„° ë° ë¡œì»¬ íŒŒì¼ ì œê±°
# ======================================================
@app.get("/delete")
def delete_file(filename: str):
    count, ids = ms.delete_document_by_filename(filename)
    return {
        "status": "DELETED" if count>0 else "NOT FOUND",
        "filename": filename,
        "deleted_count": count,
        "deleted_ids": ids
    }

# ======================================================
# â‘¢ delete_session : ì±„íŒ…ë°© ì‚­ì œ (ì„¸ì…˜ ë°ì´í„° ì „ì²´ ì‚­ì œ)
# ======================================================
@app.delete("/session/{session_id}")
def delete_session(session_id: str):
    count = ms.delete_session_data(session_id)
    return {
        "status": "DELETED",
        "session_id": session_id,
        "deleted_vectors": count
    }

# =====================================
# ğŸ’¬ ì±„íŒ… (RAG Mock)
# =====================================y
class ChatRequest(BaseModel):
    query: str
    session_id: str = "default" # ì„¸ì…˜ ID ì¶”ê°€

@app.post("/chat")
def chat_endpoint(req: ChatRequest):
    # 1. ê²€ìƒ‰ ìˆ˜í–‰ (ì„¸ì…˜ ID ì „ë‹¬)
    search_results = search(req.query, session_id=req.session_id, top_k=3)
    
    # 2. ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆëŠ”ì§€ í™•ì¸
    sources = []
    context = ""
    
    if "results" in search_results:
        for res in search_results["results"]:
            # [ìˆ˜ì •] ë‹¨ìˆœ íŒŒì¼ëª…ì´ ì•„ë‹ˆë¼ ê°ì²´ ì „ì²´(url í¬í•¨)ë¥¼ ì €ì¥
            sources.append({
                "name": res["file"],
                "url": res["url"],
                "preview": res["preview"]
            })
            context += f"- {res['preview']}\n"
    
    if not context:
        answer = "ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¬¸ì„œë¥¼ ì—…ë¡œë“œí–ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”."
    else:
        answer = f"'{req.query}'ì— ëŒ€í•´ ë¬¸ì„œì—ì„œ ì°¾ì€ ë‚´ìš©ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n\n{context}\n\n(ìœ„ ë‚´ìš©ì€ RAG ê²€ìƒ‰ ê²°ê³¼ì— ê¸°ë°˜í•©ë‹ˆë‹¤.)"

    return {
        "query": req.query,
        "answer": answer,
        "sources": sources # ì¤‘ë³µ ì œê±°
    }

# =====================================
# ğŸŒŒ Galaxy View (3D ì‹œê°í™”)
# =====================================
@app.get("/api/galaxy")
def galaxy_view(session_id: str = "default", query: Optional[str] = None):
    global collection, embeddings
    
    try:
        # 1. Milvusì—ì„œ í•´ë‹¹ ì„¸ì…˜ì˜ ëª¨ë“  ë²¡í„° ê°€ì ¸ì˜¤ê¸°
        expr = f'session_id == "{session_id}"'
        limit = 2000 # ì‹œê°í™” ìµœëŒ€ ê°œìˆ˜ ì œí•œ
        
        results = collection.query(
            expr=expr,
            output_fields=["id", "filename", "doc_type", "vector"],
            limit=limit
        )
        
        if not results:
            return []

        # 2. ë°ì´í„° ì¤€ë¹„
        vectors = []
        metadata = []
        
        for res in results:
            vectors.append(res["vector"])
            metadata.append({
                "id": str(res["id"]),
                "label": res["filename"],
                "type": res["doc_type"],
                "isQuery": False
            })
            
        # 3. ì¿¼ë¦¬ê°€ ìˆë‹¤ë©´ ë²¡í„°í™”í•˜ì—¬ ì¶”ê°€
        if query:
            qvec = embeddings.transform(query)
            if isinstance(qvec, np.ndarray):
                qvec = qvec.tolist()
            
            vectors.append(qvec)
            metadata.append({
                "id": "query",
                "label": f"Question: {query}",
                "type": "query",
                "isQuery": True
            })

        # 4. ì°¨ì› ì¶•ì†Œ (PCA: 384 -> 3)
        X = np.array(vectors)
        
        # ë°ì´í„°ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ëœë¤/ê³ ì • ìœ„ì¹˜ ë°˜í™˜
        if len(X) < 3:
            points = []
            for i, meta in enumerate(metadata):
                points.append({
                    "id": meta["id"],
                    "position": [np.random.uniform(-5, 5), np.random.uniform(-5, 5), np.random.uniform(-5, 5)],
                    "color": "#FDE047" if meta["isQuery"] else "#8B5CF6",
                    "label": meta["label"]
                })
            return points

        # PCA ìˆ˜í–‰
        # 1) ì¤‘ì•™ ì •ë ¬
        X_centered = X - np.mean(X, axis=0)
        
        # 2) SVD (Singular Value Decomposition)
        # U: (N, N), S: (K,), Vt: (K, D)
        # X ~ U * S * Vt
        # Reduced X = U[:, :3] * S[:3]
        try:
            U, S, Vt = np.linalg.svd(X_centered, full_matrices=False)
            X_3d = U[:, :3] * S[:3]
            
            # 5. ì¢Œí‘œ ì •ê·œí™” (í™”ë©´ì— ì˜ ë³´ì´ë„ë¡ ìŠ¤ì¼€ì¼ë§)
            # -10 ~ 10 ë²”ìœ„ë¡œ ì¡°ì •
            max_val = np.max(np.abs(X_3d))
            if max_val > 0:
                X_3d = (X_3d / max_val) * 15 # ìŠ¤ì¼€ì¼ ê³„ìˆ˜
            
        except Exception as e:
            print(f"PCA Error: {e}")
            return []

        # 6. ê²°ê³¼ í¬ë§·íŒ…
        points = []
        for i, coord in enumerate(X_3d):
            meta = metadata[i]
            
            # ìƒ‰ìƒ ê²°ì •
            color = "#8B5CF6" # ê¸°ë³¸ ë³´ë¼ìƒ‰
            if meta["isQuery"]:
                color = "#FDE047" # ì¿¼ë¦¬ëŠ” ë…¸ë€ìƒ‰
            elif meta["type"] in ["pdf"]:
                color = "#F43F5E" # PDFëŠ” ë¶‰ì€ìƒ‰
            elif meta["type"] in ["txt", "md"]:
                color = "#06B6D4" # í…ìŠ¤íŠ¸ëŠ” ì²­ë¡ìƒ‰
            elif meta["type"] in ["pptx", "ppt"]:
                color = "#F97316" # PPTëŠ” ì£¼í™©ìƒ‰

            points.append({
                "id": meta["id"],
                "position": coord.tolist(),
                "color": color,
                "label": meta["label"],
                "isQuery": meta["isQuery"]
            })
            
        return points

    except Exception as e:
        print(f"Galaxy View Error: {e}")
        return []

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)